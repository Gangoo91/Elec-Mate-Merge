name: Marketplace Scraper

on:
  # Scheduled runs
  schedule:
    # Materials scrape - every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 0,6,12,18 * * *'

  # Manual trigger
  workflow_dispatch:
    inputs:
      scrape_type:
        description: 'What to scrape'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - materials
          - tools
          - deals
      supplier:
        description: 'Specific supplier (leave empty for all)'
        required: false
        type: string

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

jobs:
  scrape-materials:
    name: Scrape Materials
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.scrape_type == 'all' || github.event.inputs.scrape_type == 'materials'
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/scraper/package-lock.json

      - name: Install dependencies
        working-directory: services/scraper
        run: npm ci

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run Materials Scraper
        working-directory: services/scraper
        run: |
          echo "Starting materials scrape at $(date)"
          npm run scrape:materials
          echo "Completed materials scrape at $(date)"

      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Materials scrape failed at $(date)"

  scrape-tools:
    name: Scrape Tools
    runs-on: ubuntu-latest
    if: github.event.inputs.scrape_type == 'all' || github.event.inputs.scrape_type == 'tools'
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/scraper/package-lock.json

      - name: Install dependencies
        working-directory: services/scraper
        run: npm ci

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run Tools Scraper
        working-directory: services/scraper
        run: |
          echo "Starting tools scrape at $(date)"
          npm run scrape:tools
          echo "Completed tools scrape at $(date)"

  scrape-deals:
    name: Scrape Deals
    runs-on: ubuntu-latest
    if: github.event.inputs.scrape_type == 'deals'
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/scraper/package-lock.json

      - name: Install dependencies
        working-directory: services/scraper
        run: npm ci

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run Deals Scraper
        working-directory: services/scraper
        run: |
          echo "Starting deals scrape at $(date)"
          npm run scrape:deals
          echo "Completed deals scrape at $(date)"

  scrape-single-supplier:
    name: Scrape Single Supplier
    runs-on: ubuntu-latest
    if: github.event.inputs.supplier != ''
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/scraper/package-lock.json

      - name: Install dependencies
        working-directory: services/scraper
        run: npm ci

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run Supplier Scraper
        working-directory: services/scraper
        run: |
          echo "Starting scrape for ${{ github.event.inputs.supplier }} at $(date)"
          npx tsx src/cli.ts ${{ github.event.inputs.supplier }}
          echo "Completed scrape at $(date)"

  update-scrape-timestamp:
    name: Update Last Scraped Timestamp
    runs-on: ubuntu-latest
    needs: [scrape-materials]
    if: always() && needs.scrape-materials.result == 'success'

    steps:
      - name: Update timestamp in Supabase
        run: |
          curl -X POST "${{ secrets.SUPABASE_URL }}/rest/v1/rpc/update_scrape_metadata" \
            -H "apikey: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" \
            -H "Authorization: Bearer ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{"key": "last_materials_scrape", "value": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}'
